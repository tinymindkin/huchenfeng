{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9ce264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['某网友：好，不急啊，不急。\\n', '\\n', '户晨风：感谢xxxx总的见长啊，感谢xxxx总的见长啊，再次感谢xxxx总的记录，再次感谢啊，再次感谢。好，马上开始连线啊，马上开始连线啊，不着急啊，不着急。我看连谁啊，这个吧。你好，喂，喂，123，喂，你在哪个城市？\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('/Volumes/wd/datasets/HuChenFeng-main/2025年08月/2025-08-25.md', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    print(lines[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee925b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10.md\n",
      "2025-06-14.md\n",
      "2025-06-20.md\n",
      "2025-06-15.md\n",
      "2025-06-21.md\n",
      "2025-06-11.md\n",
      "2025-06-01.md\n",
      "README.md\n",
      "2025-06-28.md\n",
      "2025-06-18.md\n",
      "2025-06-08.md\n",
      "2025-06-19.md\n",
      "2025-06-09.md\n",
      "2025-06-29.md\n",
      "2025-06-16.md\n",
      "2025-06-22.md\n",
      "2025-06-06.md\n",
      "2025-06-12.md\n",
      "2025-06-02.md\n",
      "2025-06-27.md\n",
      "2025-06-13.md\n",
      "2025-06-17.md\n",
      "2025-06-07.md\n",
      "2024-06-24.md\n",
      "2024-06-14.md\n",
      "2024-06-20.md\n",
      "2024-06-30.md\n",
      "2024-06-15.md\n",
      "2024-06-21.md\n",
      "2024-06-25.md\n",
      "README.md\n",
      "2024-06-18.md\n",
      "2024-06-19.md\n",
      "2024-06-09.md\n",
      "2024-06-16.md\n",
      "2024-06-22.md\n",
      "2024-06-26.md\n",
      "2024-06-12.md\n",
      "2024-06-27.md\n",
      "2024-06-13.md\n",
      "2024-06-23.md\n",
      "2025-05-10.md\n",
      "2025-05-24.md\n",
      "2025-05-04.md\n",
      "2025-05-30.md\n",
      "2025-05-20.md\n",
      "2025-05-14.md\n",
      "2025-05-05.md\n",
      "2025-05-31.md\n",
      "2025-05-21.md\n",
      "2025-05-25.md\n",
      "README.md\n",
      "2025-05-06.md\n",
      "2025-05-22.md\n",
      "2025-05-02.md\n",
      "2025-05-26.md\n",
      "2025-05-03.md\n",
      "2025-05-27.md\n",
      "2025-05-07.md\n",
      "2025-05-23.md\n",
      "2025-05-17.md\n",
      "2025-05-28.md\n",
      "2025-05-08.md\n",
      "2025-05-18.md\n",
      "2025-05-09.md\n",
      "2025-05-19.md\n",
      "2025-05-29.md\n",
      "2024-05-10.md\n",
      "2024-05-24.md\n",
      "2024-05-04.md\n",
      "2024-05-30.md\n",
      "2024-05-20.md\n",
      "2024-05-14.md\n",
      "2024-05-05.md\n",
      "2024-05-21.md\n",
      "2024-05-15.md\n",
      "2024-05-11.md\n",
      "2024-05-25.md\n",
      "README.md\n",
      "2024-05-06.md\n",
      "2024-05-16.md\n",
      "2024-05-12.md\n",
      "2024-05-26.md\n",
      "2024-05-13.md\n",
      "2024-05-27.md\n",
      "2024-05-07.md\n",
      "2024-05-23.md\n",
      "2024-05-17.md\n",
      "2024-05-28.md\n",
      "2024-05-08.md\n",
      "2024-05-09.md\n",
      "2024-05-19.md\n",
      "2024-05-29.md\n",
      "2023-06-22-4-INC.md\n",
      "2023-06-23-4-INC.md\n",
      "2023-06-23-6-INC.md\n",
      "2023-06-24-2-INC.md\n",
      "2023-06-24-6-INC.md\n",
      "2023-06-22-2-INC.md\n",
      "2023-06-23-2-INC.md\n",
      "2023-06-15-1-INC.md\n",
      "2023-06-20-1-INC.md\n",
      "2023-06-11.md\n",
      "2023-06-25.md\n",
      "2023-06-01.md\n",
      "2023-06-10.md\n",
      "2023-06-26-INC.md\n",
      "2023-06-24-8-INC.md\n",
      "2023-06-24-4-INC.md\n",
      "2023-06-15-3-INC.md\n",
      "2023-06-24-1-INC.md\n",
      "README.md\n",
      "2023-06-23-5-INC.md\n",
      "2023-06-22-5-INC.md\n",
      "2023-06-03.md\n",
      "2023-06-12.md\n",
      "2023-06-24-3-INC.md\n",
      "2023-06-23-7-INC.md\n",
      "2023-06-02.md\n",
      "2023-06-09.md\n",
      "2023-06-23-3-INC.md\n",
      "2023-06-22-3-INC.md\n",
      "2023-06-24-7-INC.md\n",
      "2023-06-23-1-INC.md\n",
      "2023-06-22-1-INC.md\n",
      "2023-06-15-2-INC.md\n",
      "2023-06-24-5-INC.md\n",
      "2023-06-08.md\n",
      "2023-06-20-2-INC.md\n",
      "2023-05-31.md\n",
      "2023-05-05.md\n",
      "2023-05-15.md\n",
      "2023-05-21.md\n",
      "2023-05-01.md\n",
      "2023-05-25.md\n",
      "2023-05-11.md\n",
      "2023-05-24.md\n",
      "2023-05-04.md\n",
      "2023-05-14.md\n",
      "2023-05-20.md\n",
      "2023-05-09.md\n",
      "README.md\n",
      "2023-05-19.md\n",
      "2023-05-29.md\n",
      "2023-05-08.md\n",
      "2023-05-18.md\n",
      "2023-05-13.md\n",
      "2023-05-17.md\n",
      "2023-05-23.md\n",
      "2023-05-06.md\n",
      "2023-05-16.md\n",
      "2023-05-22.md\n",
      "2023-05-02.md\n",
      "2023-05-26.md\n",
      "2023-05-12.md\n",
      "2024-10-03.md\n",
      "2024-10-02.md\n",
      "2024-10-06.md\n",
      "2024-10-01.md\n",
      "README.md\n",
      "2024-10-05.md\n",
      "2024-10-04.md\n",
      "2023-08-28.md\n",
      "2023-08-18.md\n",
      "2023-08-19.md\n",
      "2023-08-09.md\n",
      "2023-08-29.md\n",
      "2023-08-16.md\n",
      "2023-08-12.md\n",
      "2023-08-26.md\n",
      "2023-08-xx-UNK.md\n",
      "2023-08-13.md\n",
      "2023-08-27.md\n",
      "2023-08-23.md\n",
      "2023-08-17.md\n",
      "2023-08-10.md\n",
      "2023-08-24.md\n",
      "README.md\n",
      "2023-08-20.md\n",
      "2023-08-30.md\n",
      "2023-08-21.md\n",
      "2023-08-15.md\n",
      "2023-08-05.md\n",
      "2023-08-31.md\n",
      "2023-08-11.md\n",
      "2023-08-25.md\n",
      "2025-01-11.md\n",
      "2025-01-15.md\n",
      "2025-01-21.md\n",
      "2025-01-14.md\n",
      "2025-01-20.md\n",
      "2025-01-10.md\n",
      "2025-01-17.md\n",
      "2025-01-23.md\n",
      "README.md\n",
      "2025-01-13.md\n",
      "2025-01-12.md\n",
      "2025-01-16.md\n",
      "2025-01-22.md\n",
      "2025-01-19.md\n",
      "2025-01-09.md\n",
      "2025-01-18.md\n",
      "2024-01-01.md\n",
      "2024-01-15.md\n",
      "2024-01-21.md\n",
      "2024-01-14.md\n",
      "2024-01-20.md\n",
      "2024-01-04.md\n",
      "2024-01-24.md\n",
      "README.md\n",
      "2024-01-27.md\n",
      "2024-01-13.md\n",
      "2024-01-03-INC.md\n",
      "2024-01-02.md\n",
      "2024-01-16.md\n",
      "2024-01-22.md\n",
      "2024-01-19.md\n",
      "2024-01-18.md\n",
      "2024-01-28.md\n",
      "2024-08-03.md\n",
      "2024-08-07.md\n",
      "2024-08-12.md\n",
      "2024-08-02.md\n",
      "2024-08-09.md\n",
      "2024-08-29.md\n",
      "2024-08-08.md\n",
      "README.md\n",
      "2024-08-31.md\n",
      "2024-08-11.md\n",
      "2024-08-01.md\n",
      "2024-08-10.md\n",
      "2024-08-04.md\n",
      "2025-02-11.md\n",
      "2025-02-25.md\n",
      "2025-02-15.md\n",
      "2025-02-14.md\n",
      "2025-02-10.md\n",
      "2025-02-24.md\n",
      "README.md\n",
      "2025-02-09.md\n",
      "2025-02-19.md\n",
      "2025-02-08.md\n",
      "2025-02-18.md\n",
      "2025-02-28.md\n",
      "2025-02-07.md\n",
      "2025-02-23.md\n",
      "2025-02-17.md\n",
      "2025-02-13.md\n",
      "2025-02-27.md\n",
      "2025-02-12.md\n",
      "2025-02-26.md\n",
      "2025-02-06.md\n",
      "2025-02-16.md\n",
      "2023-10-27.md\n",
      "2023-10-18.md\n",
      "2023-10-29.md\n",
      "2023-10-19.md\n",
      "README.md\n",
      "2023-10-30.md\n",
      "2023-10-20.md\n",
      "2023-10-31.md\n",
      "2025-08-13.md\n",
      "2025-08-17.md\n",
      "2025-08-23.md\n",
      "2025-08-07.md\n",
      "2025-08-16.md\n",
      "2025-08-22.md\n",
      "2025-08-26.md\n",
      "2025-08-12.md\n",
      "2025-08-19.md\n",
      "2025-08-09.md\n",
      "2025-08-18.md\n",
      "2025-08-08.md\n",
      "README.md\n",
      "2025-08-15.md\n",
      "2025-08-21.md\n",
      "2025-08-25.md\n",
      "2025-08-11.md\n",
      "2025-08-24.md\n",
      "2025-08-10.md\n",
      "2025-08-14.md\n",
      "2025-08-20.md\n",
      "2024-02-15.md\n",
      "2024-02-20.md\n",
      "README.md\n",
      "2024-02-29.md\n",
      "2024-02-18.md\n",
      "2024-02-17.md\n",
      "2024-02-03.md\n",
      "2024-02-22.md\n",
      "2024-02-16.md\n",
      "2025-03-31.md\n",
      "2025-03-05.md\n",
      "2025-03-21.md\n",
      "2025-03-01.md\n",
      "2025-03-25.md\n",
      "2025-03-11.md\n",
      "2025-03-24.md\n",
      "2025-03-10.md\n",
      "2025-03-30.md\n",
      "2025-03-04.md\n",
      "2025-03-20.md\n",
      "2025-03-03.md\n",
      "README.md\n",
      "2025-03-27.md\n",
      "2025-03-07.md\n",
      "2025-03-17.md\n",
      "2025-03-06.md\n",
      "2025-03-16.md\n",
      "2025-03-22.md\n",
      "2025-03-02.md\n",
      "2025-03-26.md\n",
      "2025-03-09.md\n",
      "2025-03-29.md\n",
      "2025-03-28.md\n",
      "2025-03-08.md\n",
      "2024-09-29.md\n",
      "2024-09-19.md\n",
      "2024-09-09.md\n",
      "2024-09-28.md\n",
      "2024-09-17.md\n",
      "2024-09-13.md\n",
      "2024-09-27.md\n",
      "2024-09-12.md\n",
      "2024-09-26.md\n",
      "2024-09-22.md\n",
      "2024-09-16.md\n",
      "README.md\n",
      "2024-09-11.md\n",
      "2024-09-25.md\n",
      "2024-09-21.md\n",
      "2024-09-15.md\n",
      "2024-09-20.md\n",
      "2024-09-14.md\n",
      "2024-09-04.md\n",
      "2024-09-30.md\n",
      "2024-09-10.md\n",
      "2024-09-24.md\n",
      "2023-11-28.md\n",
      "2023-11-08.md\n",
      "2023-11-18.md\n",
      "2023-11-19.md\n",
      "2023-11-06.md\n",
      "2023-11-22.md\n",
      "2023-11-02.md\n",
      "2023-11-26.md\n",
      "2023-11-12.md\n",
      "2023-11-27.md\n",
      "2023-11-13.md\n",
      "2023-11-07.md\n",
      "2023-11-17.md\n",
      "2023-11-23.md\n",
      "README.md\n",
      "2023-11-24.md\n",
      "2023-11-10.md\n",
      "2023-11-20.md\n",
      "2023-11-15.md\n",
      "2023-11-21.md\n",
      "2023-11-01.md\n",
      "2023-11-25.md\n",
      "2023-11-11.md\n",
      "2024-03-31.md\n",
      "2024-03-15.md\n",
      "2024-03-21.md\n",
      "2024-03-25.md\n",
      "2024-03-24.md\n",
      "2024-03-30.md\n",
      "2024-03-04.md\n",
      "2024-03-14.md\n",
      "2024-03-20.md\n",
      "README.md\n",
      "2024-03-27.md\n",
      "2024-03-13.md\n",
      "2024-03-07.md\n",
      "2024-03-23.md\n",
      "2024-03-16.md\n",
      "2024-03-22.md\n",
      "2024-03-02.md\n",
      "2024-03-12.md\n",
      "2024-03-19.md\n",
      "2024-03-29.md\n",
      "2024-03-28.md\n",
      "2024-03-18.md\n",
      "2025-09-08.md\n",
      "2025-09-07.md\n",
      "2025-09-12.md\n",
      "README.md\n",
      "2025-09-11.md\n",
      "2025-09-14.md\n",
      "2025-09-10.md\n",
      "2023-12-22.md\n",
      "2023-12-16.md\n",
      "2023-12-12.md\n",
      "2023-12-26.md\n",
      "2023-12-13.md\n",
      "2023-12-27.md\n",
      "2023-12-03.md\n",
      "2023-12-23.md\n",
      "2023-12-28.md\n",
      "2023-12-29.md\n",
      "README.md\n",
      "2023-12-24.md\n",
      "2023-12-20.md\n",
      "2023-12-14.md\n",
      "2023-12-30.md\n",
      "2023-12-21.md\n",
      "2023-12-05.md\n",
      "2023-12-31.md\n",
      "2023-12-11.md\n",
      "2023-12-25.md\n",
      "2023-03-10.md\n",
      "2023-03-11.md\n",
      "README.md\n",
      "2023-03-12-INC.md\n",
      "2023-03-13.md\n",
      "2023-09-03.md\n",
      "README.md\n",
      "2023-09-04.md\n",
      "2023-09-05.md\n",
      "2023-04-15.md\n",
      "2023-04-30.md\n",
      "README.md\n",
      "2023-04-17.md\n",
      "2023-04-16.md\n",
      "2023-04-19.md\n",
      "2023-04-18.md\n",
      "2023-07-25.md\n",
      "2023-07-11.md\n",
      "2023-07-15.md\n",
      "2023-07-31.md\n",
      "2023-07-14.md\n",
      "2023-07-30.md\n",
      "2023-07-29.md\n",
      "README.md\n",
      "2023-07-28.md\n",
      "2023-07-17.md\n",
      "2023-07-27.md\n",
      "2023-07-13.md\n",
      "2023-07-26.md\n",
      "2023-07-12.md\n",
      "2023-07-16.md\n",
      "2025-04-30.md\n",
      "2025-04-04.md\n",
      "2025-04-14.md\n",
      "2025-04-20.md\n",
      "2025-04-24.md\n",
      "2025-04-01.md\n",
      "2025-04-25.md\n",
      "2025-04-05.md\n",
      "2025-04-15.md\n",
      "2025-04-21.md\n",
      "README.md\n",
      "2025-04-08.md\n",
      "2025-04-18.md\n",
      "2025-04-28.md\n",
      "2025-04-29.md\n",
      "2025-04-09.md\n",
      "2025-04-19.md\n",
      "2025-04-02.md\n",
      "2025-04-26.md\n",
      "2025-04-12.md\n",
      "2025-04-06.md\n",
      "2025-04-16.md\n",
      "2025-04-22.md\n",
      "2025-04-07.md\n",
      "2025-04-17.md\n",
      "2025-04-23.md\n",
      "2025-04-03.md\n",
      "2025-04-27.md\n",
      "2025-04-13.md\n",
      "2024-04-10.md\n",
      "2024-04-01.md\n",
      "2024-04-11.md\n",
      "2024-04-05.md\n",
      "README.md\n",
      "2024-04-08.md\n",
      "2024-04-09.md\n",
      "2024-04-02.md\n",
      "2024-04-06.md\n",
      "2024-04-07.md\n",
      "2025-07-20.md\n",
      "2025-07-14.md\n",
      "2025-07-04.md\n",
      "2025-07-10.md\n",
      "2025-07-11.md\n",
      "2025-07-21.md\n",
      "2025-07-15.md\n",
      "2025-07-05.md\n",
      "README.md\n",
      "2025-07-02.md\n",
      "2025-07-22.md\n",
      "2025-07-16.md\n",
      "2025-07-17.md\n",
      "2025-07-03.md\n",
      "2025-07-18.md\n",
      "2025-07-19.md\n",
      "2024-07-20.md\n",
      "2024-07-14.md\n",
      "2024-07-04.md\n",
      "2024-07-30.md\n",
      "2024-07-24.md\n",
      "2024-07-11.md\n",
      "2024-07-21.md\n",
      "2024-07-05.md\n",
      "2024-07-31.md\n",
      "README.md\n",
      "2024-07-12.md\n",
      "2024-07-26.md\n",
      "2024-07-02.md\n",
      "2024-07-22.md\n",
      "2024-07-06.md\n",
      "2024-07-23.md\n",
      "2024-07-07.md\n",
      "2024-07-27.md\n",
      "2024-07-03.md\n",
      "2024-07-08.md\n",
      "2024-07-29.md\n",
      "2024-07-19.md\n",
      "2024-07-09.md\n",
      "Done！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('../database/raw_dialogues.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the table, clearing it if it already exists\n",
    "cursor.execute('''\n",
    "DROP TABLE IF EXISTS raw_dialogues\n",
    "''')\n",
    "cursor.execute('''\n",
    "CREATE TABLE raw_dialogues (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    wangyou VARCHAR NOT NULL,\n",
    "    huchenfeng VARCHAR NOT NULL,\n",
    "    source TEXT(100)\n",
    ")\n",
    "''')\n",
    "\n",
    "# Traverse directories and files\n",
    "for folder in os.listdir(\"../\"):\n",
    "    if re.match(r\"\\d{4}\", folder):\n",
    "        folder_path = os.path.join(\"../\", folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if re.match(r\"\\d{4}\", filename):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    lines = file.readlines()\n",
    "                    lines = [line.replace(\"\\n\", \"\") for line in lines if line != \"\\n\"]\n",
    "                    for index, line in enumerate(lines):\n",
    "                        if index != 0:\n",
    "                            if line.startswith(\"户晨风\") and lines[index - 1].startswith(\"某网友\"):\n",
    "                                cursor.execute('''\n",
    "                                INSERT INTO raw_dialogues (wangyou, huchenfeng, source)\n",
    "                                VALUES (?, ?, ?)\n",
    "                                ''', (\n",
    "                                    lines[index - 1].replace(\"某网友：\", \"\"),\n",
    "                                    line.replace(\"户晨风：\", \"\"),\n",
    "                                    filename\n",
    "                                ))\n",
    "            print(filename)\n",
    "conn.commit()\n",
    "\n",
    "# Commit changes and close the connection\n",
    "\n",
    "conn.close()\n",
    "print(\"Done！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d31d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huchenfeng.length >= 100: 25216\n",
      "wangyou.length >= 100: 16987\n",
      "huchenfeng.length >= 100 and wangyou.length >= 100: 3535\n",
      "huchenfeng.length >= 50: 51226\n",
      "wangyou.length >= 50: 41720\n",
      "huchenfeng.length >= 50 and wangyou.length >= 50: 13937\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('../database/raw_dialogues.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Initialize counters\n",
    "count_huchenfeng_100 = 0\n",
    "count_wangyou_100 = 0\n",
    "count_both_100 = 0\n",
    "\n",
    "count_huchenfeng_50 = 0\n",
    "count_wangyou_50 = 0\n",
    "count_both_50 = 0\n",
    "\n",
    "# Fetch and analyze data in batches\n",
    "cursor.execute('SELECT * FROM raw_dialogues')\n",
    "batch_size = 1000  # define a suitable batch size\n",
    "while True:\n",
    "    rows = cursor.fetchmany(batch_size)\n",
    "    if not rows:\n",
    "        break\n",
    "    count_huchenfeng_100 += sum(len(row[2]) >= 100 for row in rows)\n",
    "    count_wangyou_100 += sum(len(row[1]) >= 100 for row in rows)\n",
    "    count_both_100 += sum(len(row[2]) >= 100 and len(row[1]) >= 100 for row in rows)\n",
    "\n",
    "    count_huchenfeng_50 += sum(len(row[2]) >= 50 for row in rows)\n",
    "    count_wangyou_50 += sum(len(row[1]) >= 50 for row in rows)\n",
    "    count_both_50 += sum(len(row[2]) >= 50 and len(row[1]) >= 50 for row in rows)\n",
    "\n",
    "print('huchenfeng.length >= 100:', count_huchenfeng_100)\n",
    "print('wangyou.length >= 100:', count_wangyou_100)\n",
    "print('huchenfeng.length >= 100 and wangyou.length >= 100:', count_both_100)\n",
    "\n",
    "print('huchenfeng.length >= 50:', count_huchenfeng_50)\n",
    "print('wangyou.length >= 50:', count_wangyou_50)\n",
    "print('huchenfeng.length >= 50 and wangyou.length >= 50:', count_both_50)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4ecfa",
   "metadata": {},
   "source": [
    "## 过滤数据\n",
    "1. 数量过滤 ：挑出huchenfeng.length >= 50 的row : ok\n",
    "到这个表\n",
    "filtered_dialogues:\n",
    "      - id : 自增\n",
    "      - wangyou ： varchar notnull.  -- 网友发言\n",
    "      - huchenfeng： varchar notnull  -- 户晨风发言 \n",
    "      - source : TEXT(100) --来源（文件名） \n",
    "for dialogue in raw_dialogues:\n",
    "    if dialogue.huchenfeng >= 50 :\n",
    "        insert into filtered_dialogues(wangyou,huchenfeng,source) values(dialogue.wangyou,dialogue.huchenfeng,dialogue.source)\n",
    "2. 规整化 + 去噪 + 分段\n",
    "   ```markdown\n",
    "   这是一个主播的话，其中可能会有一些读评论，背景音乐。请把这些内容过滤掉。如果没有就不需要。\n",
    "   将转化不正确的去处，给我原来的话语，要保留本来的内容,只需将错误的改正就好。不要改变原来的话。\n",
    "   \n",
    "   ```\n",
    "\n",
    "if 没有分段：\n",
    "    问答对 可以用于训练\n",
    "    那么新数据库的 input:就放置 wanyou \n",
    "else，分段后：\n",
    "    原来的问题目就不能用了,需要重新生成。\n",
    "\n",
    "    数据模型:\n",
    "    clear_huchenfeng_dialogues: （只有户晨风的内容是干净的对话）\n",
    "         - id : 自增\n",
    "         - wangyou ： varchar notnull.  -- 网友发言\n",
    "         - huchenfeng： varchar notnull  -- 户晨风发言 \n",
    "         - source : TEXT(100) --来源（文件名）\n",
    "         -  filtered_dialogue_id : 和 filtered_dialogues.id 关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c23c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理 294 条符合条件的对话...\n",
      "已处理 545 条符合条件的对话...\n",
      "已处理 794 条符合条件的对话...\n",
      "已处理 1098 条符合条件的对话...\n",
      "已处理 1405 条符合条件的对话...\n",
      "已处理 1671 条符合条件的对话...\n",
      "已处理 1961 条符合条件的对话...\n",
      "已处理 2174 条符合条件的对话...\n",
      "已处理 2422 条符合条件的对话...\n",
      "已处理 2722 条符合条件的对话...\n",
      "已处理 3021 条符合条件的对话...\n",
      "已处理 3273 条符合条件的对话...\n",
      "已处理 3619 条符合条件的对话...\n",
      "已处理 3929 条符合条件的对话...\n",
      "已处理 4202 条符合条件的对话...\n",
      "已处理 4480 条符合条件的对话...\n",
      "已处理 4748 条符合条件的对话...\n",
      "已处理 5007 条符合条件的对话...\n",
      "已处理 5235 条符合条件的对话...\n",
      "已处理 5500 条符合条件的对话...\n",
      "已处理 5803 条符合条件的对话...\n",
      "已处理 6045 条符合条件的对话...\n",
      "已处理 6286 条符合条件的对话...\n",
      "已处理 6540 条符合条件的对话...\n",
      "已处理 6842 条符合条件的对话...\n",
      "已处理 7100 条符合条件的对话...\n",
      "已处理 7339 条符合条件的对话...\n",
      "已处理 7613 条符合条件的对话...\n",
      "已处理 7859 条符合条件的对话...\n",
      "已处理 8186 条符合条件的对话...\n",
      "已处理 8492 条符合条件的对话...\n",
      "已处理 8810 条符合条件的对话...\n",
      "已处理 9090 条符合条件的对话...\n",
      "已处理 9411 条符合条件的对话...\n",
      "已处理 9723 条符合条件的对话...\n",
      "已处理 9995 条符合条件的对话...\n",
      "已处理 10320 条符合条件的对话...\n",
      "已处理 10648 条符合条件的对话...\n",
      "已处理 10795 条符合条件的对话...\n",
      "已处理 10876 条符合条件的对话...\n",
      "已处理 11009 条符合条件的对话...\n",
      "已处理 11117 条符合条件的对话...\n",
      "已处理 11253 条符合条件的对话...\n",
      "已处理 11369 条符合条件的对话...\n",
      "已处理 11484 条符合条件的对话...\n",
      "已处理 11587 条符合条件的对话...\n",
      "已处理 11763 条符合条件的对话...\n",
      "已处理 12059 条符合条件的对话...\n",
      "已处理 12233 条符合条件的对话...\n",
      "已处理 12364 条符合条件的对话...\n",
      "已处理 12494 条符合条件的对话...\n",
      "已处理 12708 条符合条件的对话...\n",
      "已处理 12937 条符合条件的对话...\n",
      "已处理 13147 条符合条件的对话...\n",
      "已处理 13334 条符合条件的对话...\n",
      "已处理 13522 条符合条件的对话...\n",
      "已处理 13756 条符合条件的对话...\n",
      "已处理 13990 条符合条件的对话...\n",
      "已处理 14213 条符合条件的对话...\n",
      "已处理 14448 条符合条件的对话...\n",
      "已处理 14663 条符合条件的对话...\n",
      "已处理 14928 条符合条件的对话...\n",
      "已处理 15129 条符合条件的对话...\n",
      "已处理 15349 条符合条件的对话...\n",
      "已处理 15608 条符合条件的对话...\n",
      "已处理 15849 条符合条件的对话...\n",
      "已处理 16087 条符合条件的对话...\n",
      "已处理 16368 条符合条件的对话...\n",
      "已处理 16631 条符合条件的对话...\n",
      "已处理 16882 条符合条件的对话...\n",
      "已处理 17195 条符合条件的对话...\n",
      "已处理 17450 条符合条件的对话...\n",
      "已处理 17751 条符合条件的对话...\n",
      "已处理 18003 条符合条件的对话...\n",
      "已处理 18330 条符合条件的对话...\n",
      "已处理 18620 条符合条件的对话...\n",
      "已处理 18933 条符合条件的对话...\n",
      "已处理 19212 条符合条件的对话...\n",
      "已处理 19551 条符合条件的对话...\n",
      "已处理 19790 条符合条件的对话...\n",
      "已处理 20016 条符合条件的对话...\n",
      "已处理 20277 条符合条件的对话...\n",
      "已处理 20554 条符合条件的对话...\n",
      "已处理 20789 条符合条件的对话...\n",
      "已处理 21059 条符合条件的对话...\n",
      "已处理 21325 条符合条件的对话...\n",
      "已处理 21549 条符合条件的对话...\n",
      "已处理 21812 条符合条件的对话...\n",
      "已处理 22052 条符合条件的对话...\n",
      "已处理 22324 条符合条件的对话...\n",
      "已处理 22538 条符合条件的对话...\n",
      "已处理 22795 条符合条件的对话...\n",
      "已处理 23137 条符合条件的对话...\n",
      "已处理 23403 条符合条件的对话...\n",
      "已处理 23640 条符合条件的对话...\n",
      "已处理 23886 条符合条件的对话...\n",
      "已处理 24174 条符合条件的对话...\n",
      "已处理 24458 条符合条件的对话...\n",
      "已处理 24673 条符合条件的对话...\n",
      "已处理 24956 条符合条件的对话...\n",
      "已处理 25233 条符合条件的对话...\n",
      "已处理 25498 条符合条件的对话...\n",
      "已处理 25748 条符合条件的对话...\n",
      "已处理 25986 条符合条件的对话...\n",
      "已处理 26254 条符合条件的对话...\n",
      "已处理 26516 条符合条件的对话...\n",
      "已处理 26837 条符合条件的对话...\n",
      "已处理 27170 条符合条件的对话...\n",
      "已处理 27432 条符合条件的对话...\n",
      "已处理 27667 条符合条件的对话...\n",
      "已处理 27885 条符合条件的对话...\n",
      "已处理 28115 条符合条件的对话...\n",
      "已处理 28370 条符合条件的对话...\n",
      "已处理 28618 条符合条件的对话...\n",
      "已处理 28892 条符合条件的对话...\n",
      "已处理 29143 条符合条件的对话...\n",
      "已处理 29399 条符合条件的对话...\n",
      "已处理 29667 条符合条件的对话...\n",
      "已处理 29938 条符合条件的对话...\n",
      "已处理 30265 条符合条件的对话...\n",
      "已处理 30509 条符合条件的对话...\n",
      "已处理 30755 条符合条件的对话...\n",
      "已处理 30963 条符合条件的对话...\n",
      "已处理 31243 条符合条件的对话...\n",
      "已处理 31497 条符合条件的对话...\n",
      "已处理 31716 条符合条件的对话...\n",
      "已处理 31932 条符合条件的对话...\n",
      "已处理 32152 条符合条件的对话...\n",
      "已处理 32356 条符合条件的对话...\n",
      "已处理 32583 条符合条件的对话...\n",
      "已处理 32830 条符合条件的对话...\n",
      "已处理 33105 条符合条件的对话...\n",
      "已处理 33483 条符合条件的对话...\n",
      "已处理 33773 条符合条件的对话...\n",
      "已处理 34147 条符合条件的对话...\n",
      "已处理 34477 条符合条件的对话...\n",
      "已处理 34815 条符合条件的对话...\n",
      "已处理 35126 条符合条件的对话...\n",
      "已处理 35373 条符合条件的对话...\n",
      "已处理 35594 条符合条件的对话...\n",
      "已处理 35807 条符合条件的对话...\n",
      "已处理 36057 条符合条件的对话...\n",
      "已处理 36291 条符合条件的对话...\n",
      "已处理 36553 条符合条件的对话...\n",
      "已处理 36795 条符合条件的对话...\n",
      "已处理 37021 条符合条件的对话...\n",
      "已处理 37292 条符合条件的对话...\n",
      "已处理 37505 条符合条件的对话...\n",
      "已处理 37729 条符合条件的对话...\n",
      "已处理 37938 条符合条件的对话...\n",
      "已处理 38165 条符合条件的对话...\n",
      "已处理 38439 条符合条件的对话...\n",
      "已处理 38767 条符合条件的对话...\n",
      "已处理 39027 条符合条件的对话...\n",
      "已处理 39381 条符合条件的对话...\n",
      "已处理 39640 条符合条件的对话...\n",
      "已处理 39876 条符合条件的对话...\n",
      "已处理 39999 条符合条件的对话...\n",
      "已处理 40243 条符合条件的对话...\n",
      "已处理 40437 条符合条件的对话...\n",
      "已处理 40573 条符合条件的对话...\n",
      "已处理 40686 条符合条件的对话...\n",
      "已处理 40790 条符合条件的对话...\n",
      "已处理 40968 条符合条件的对话...\n",
      "已处理 41140 条符合条件的对话...\n",
      "已处理 41328 条符合条件的对话...\n",
      "已处理 41530 条符合条件的对话...\n",
      "已处理 41700 条符合条件的对话...\n",
      "已处理 41938 条符合条件的对话...\n",
      "已处理 42176 条符合条件的对话...\n",
      "已处理 42421 条符合条件的对话...\n",
      "已处理 42705 条符合条件的对话...\n",
      "已处理 42973 条符合条件的对话...\n",
      "已处理 43234 条符合条件的对话...\n",
      "已处理 43458 条符合条件的对话...\n",
      "已处理 43738 条符合条件的对话...\n",
      "已处理 44018 条符合条件的对话...\n",
      "已处理 44340 条符合条件的对话...\n",
      "已处理 44613 条符合条件的对话...\n",
      "已处理 44890 条符合条件的对话...\n",
      "已处理 45239 条符合条件的对话...\n",
      "已处理 45495 条符合条件的对话...\n",
      "已处理 45803 条符合条件的对话...\n",
      "已处理 46054 条符合条件的对话...\n",
      "已处理 46327 条符合条件的对话...\n",
      "已处理 46615 条符合条件的对话...\n",
      "已处理 46871 条符合条件的对话...\n",
      "已处理 47164 条符合条件的对话...\n",
      "已处理 47466 条符合条件的对话...\n",
      "已处理 47691 条符合条件的对话...\n",
      "已处理 47941 条符合条件的对话...\n",
      "已处理 48251 条符合条件的对话...\n",
      "已处理 48531 条符合条件的对话...\n",
      "已处理 48820 条符合条件的对话...\n",
      "已处理 49140 条符合条件的对话...\n",
      "已处理 49460 条符合条件的对话...\n",
      "已处理 49757 条符合条件的对话...\n",
      "已处理 50026 条符合条件的对话...\n",
      "已处理 50319 条符合条件的对话...\n",
      "已处理 50571 条符合条件的对话...\n",
      "已处理 50874 条符合条件的对话...\n",
      "已处理 51178 条符合条件的对话...\n",
      "已处理 51226 条符合条件的对话...\n",
      "\n",
      "完成！共过滤了 51226 条对话，huchenfeng.length >= 50\n",
      "数据已保存到 filtered_dialogues 表\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('../database/raw_dialogues.db')\n",
    "cursor_read = conn.cursor()  # 用于读取\n",
    "cursor_write = conn.cursor()  # 用于写入\n",
    "\n",
    "# Create the filtered_dialogues table\n",
    "cursor_write.execute('''\n",
    "DROP TABLE IF EXISTS filtered_dialogues\n",
    "''')\n",
    "\n",
    "cursor_write.execute('''\n",
    "CREATE TABLE filtered_dialogues (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    wangyou VARCHAR NOT NULL,\n",
    "    huchenfeng VARCHAR NOT NULL,\n",
    "    source TEXT(100)\n",
    ")\n",
    "''')\n",
    "\n",
    "# Read from raw_dialogues and filter by huchenfeng length >= 50\n",
    "cursor_read.execute('SELECT wangyou, huchenfeng, source FROM raw_dialogues')\n",
    "\n",
    "filtered_count = 0\n",
    "batch_size = 1000\n",
    "\n",
    "while True:\n",
    "    rows = cursor_read.fetchmany(batch_size)\n",
    "    if not rows:\n",
    "        break\n",
    "    \n",
    "    # Filter rows where huchenfeng length >= 50\n",
    "    filtered_rows = [(row[0], row[1], row[2]) for row in rows if len(row[1]) >= 50]\n",
    "    \n",
    "    # Insert filtered rows into filtered_dialogues\n",
    "    if filtered_rows:\n",
    "        cursor_write.executemany('''\n",
    "        INSERT INTO filtered_dialogues (wangyou, huchenfeng, source)\n",
    "        VALUES (?, ?, ?)\n",
    "        ''', filtered_rows)\n",
    "        filtered_count += len(filtered_rows)\n",
    "        print(f\"已处理 {filtered_count} 条符合条件的对话...\")\n",
    "\n",
    "# Commit changes\n",
    "conn.commit()\n",
    "\n",
    "print(f\"\\n完成！共过滤了 {filtered_count} 条对话，huchenfeng.length >= 50\")\n",
    "print(\"数据已保存到 filtered_dialogues 表\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56f8a4",
   "metadata": {},
   "source": [
    "\n",
    "## 形成待处理的jsonl\n",
    "\n",
    "数据格式：\n",
    "    {'id':1,'huchenfeng':'',\"source\":''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fafb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database at: dataset/database/raw_dialogues.db\n",
      "Writing to: dataset/database/filter_dialogues.jsonl\n",
      "Successfully wrote 51226 records to dataset/database/filter_dialogues.jsonl\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "db_path = 'dataset/database/raw_dialogues.db'\n",
    "jsonl_path = 'dataset/database/filter_dialogues.jsonl'\n",
    "\n",
    "# Check if database exists at the expected path, if not try the path used in previous cells\n",
    "if not os.path.exists(db_path):\n",
    "    if os.path.exists('../database/raw_dialogues.db'):\n",
    "        db_path = '../database/raw_dialogues.db'\n",
    "        # Adjust jsonl path to match relative location if needed, but user specified dataset/database/filter_dialogues.jsonl\n",
    "        # Assuming if running from subdir, dataset/database might be accessible differently? \n",
    "        # Let's just stick to the user request's implied path for output, but try to find DB.\n",
    "\n",
    "print(f\"Using database at: {db_path}\")\n",
    "print(f\"Writing to: {jsonl_path}\")\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Query the data\n",
    "    cursor.execute(\"SELECT id, huchenfeng, source FROM filtered_dialogues\")\n",
    "\n",
    "    # Write to JSONL\n",
    "    count = 0\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        while True:\n",
    "            rows = cursor.fetchmany(1000)\n",
    "            if not rows:\n",
    "                break\n",
    "            for row in rows:\n",
    "                record = {\n",
    "                    'id': row[0],\n",
    "                    'huchenfeng': row[1],\n",
    "                    'source': row[2]\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "                count += 1\n",
    "\n",
    "    print(f\"Successfully wrote {count} records to {jsonl_path}\")\n",
    "\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5653d18",
   "metadata": {},
   "source": [
    "## 生成用于训练的数据库\n",
    "1. 读取 filtered_dialogues 表(id,wangyou,huchenfeng,source) \n",
    "2. 创建一个新的表 train_dialogues(id,huchenfeng,processed_data,status(default:0),source,created_at,processed_at) ,其中huchenfeng存filtered_dialogues.huchenfeng,source存filtered_dialogues.source,created_at存当前时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b747f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database at: dataset/database/raw_dialogues.db\n",
      "Created train_dialogues table\n",
      "已插入 1000 条记录...\n",
      "已插入 2000 条记录...\n",
      "已插入 3000 条记录...\n",
      "已插入 4000 条记录...\n",
      "已插入 5000 条记录...\n",
      "已插入 6000 条记录...\n",
      "已插入 7000 条记录...\n",
      "已插入 8000 条记录...\n",
      "已插入 9000 条记录...\n",
      "已插入 10000 条记录...\n",
      "已插入 11000 条记录...\n",
      "已插入 12000 条记录...\n",
      "已插入 13000 条记录...\n",
      "已插入 14000 条记录...\n",
      "已插入 15000 条记录...\n",
      "已插入 16000 条记录...\n",
      "已插入 17000 条记录...\n",
      "已插入 18000 条记录...\n",
      "已插入 19000 条记录...\n",
      "已插入 20000 条记录...\n",
      "已插入 21000 条记录...\n",
      "已插入 22000 条记录...\n",
      "已插入 23000 条记录...\n",
      "已插入 24000 条记录...\n",
      "已插入 25000 条记录...\n",
      "已插入 26000 条记录...\n",
      "已插入 27000 条记录...\n",
      "已插入 28000 条记录...\n",
      "已插入 29000 条记录...\n",
      "已插入 30000 条记录...\n",
      "已插入 31000 条记录...\n",
      "已插入 32000 条记录...\n",
      "已插入 33000 条记录...\n",
      "已插入 34000 条记录...\n",
      "已插入 35000 条记录...\n",
      "已插入 36000 条记录...\n",
      "已插入 37000 条记录...\n",
      "已插入 38000 条记录...\n",
      "已插入 39000 条记录...\n",
      "已插入 40000 条记录...\n",
      "已插入 41000 条记录...\n",
      "已插入 42000 条记录...\n",
      "已插入 43000 条记录...\n",
      "已插入 44000 条记录...\n",
      "已插入 45000 条记录...\n",
      "已插入 46000 条记录...\n",
      "已插入 47000 条记录...\n",
      "已插入 48000 条记录...\n",
      "已插入 49000 条记录...\n",
      "已插入 50000 条记录...\n",
      "已插入 51000 条记录...\n",
      "已插入 51226 条记录...\n",
      "\n",
      "完成！共插入 51226 条记录到 train_dialogues 表\n",
      "验证：train_dialogues 表中共有 51226 条记录\n",
      "\n",
      "示例数据：\n",
      "  ID: 1, 户晨风: 你读大学，你有点含金量也行，说白了水个学历，学校就是给你发个证，这个证就没有任何含金量。你说我没读过..., 状态: None, 来源: 0, 创建时间: 2025-06-10.md\n",
      "  ID: 2, 户晨风: 这个世界上人没干过的事情多呢，怎么着都没资格评论了？你个抖音上看新闻都无法评论啊？人没干过事情多呢，..., 状态: None, 来源: 0, 创建时间: 2025-06-10.md\n",
      "  ID: 3, 户晨风: 你看，首先我是个人，我是人我就有这个权利，法律赋予我的权利去评价。你要剥夺我的权利对不对？我说了你可..., 状态: None, 来源: 0, 创建时间: 2025-06-10.md\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "生成用于训练的数据库\n",
    "1. 读取 filtered_dialogues 表(id,wangyou,huchenfeng,source) \n",
    "2. 创建一个新的表 train_dialogues(id,huchenfeng,processed_data,status,source,created_at,processed_at)\n",
    "\"\"\"\n",
    "db_path='dataset/database/raw_dialogues.db'\n",
    "# Check if database exists at the expected path\n",
    "if not os.path.exists(db_path):\n",
    "    # Try alternative path used in notebook\n",
    "    if os.path.exists('../database/raw_dialogues.db'):\n",
    "        db_path = '../database/raw_dialogues.db'\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Database not found at {db_path}\")\n",
    "\n",
    "print(f\"Using database at: {db_path}\")\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor_write = conn.cursor()\n",
    "cursor_read = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Drop and create the train_dialogues table\n",
    "    cursor_write.execute('DROP TABLE IF EXISTS train_dialogues')\n",
    "    \n",
    "    cursor_write.execute('''\n",
    "    CREATE TABLE train_dialogues (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        huchenfeng VARCHAR NOT NULL,\n",
    "        processed_data TEXT,\n",
    "        model_version TEXT(100),\n",
    "        status INTEGER DEFAULT 0,\n",
    "        source TEXT(100),\n",
    "        created_at TIMESTAMP NOT NULL,\n",
    "        processed_at TIMESTAMP\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    print(\"Created train_dialogues table\")\n",
    "    \n",
    "    # Get current timestamp\n",
    "    created_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Read from filtered_dialogues\n",
    "    cursor_read.execute('SELECT id, huchenfeng, source FROM filtered_dialogues')\n",
    "    \n",
    "    inserted_count = 0\n",
    "    batch_size = 1000\n",
    "    \n",
    "    while True:\n",
    "        rows = cursor_read.fetchmany(batch_size)\n",
    "        if not rows:\n",
    "            break\n",
    "        \n",
    "        # Prepare data for insertion\n",
    "        data_to_insert = [\n",
    "            (row[1], None, 0, row[2], created_at, None) \n",
    "            for row in rows\n",
    "        ]\n",
    "        \n",
    "        # Insert into train_dialogues\n",
    "        cursor_write.executemany('''\n",
    "        INSERT INTO train_dialogues (huchenfeng, processed_data, status, source, created_at, processed_at)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', data_to_insert)\n",
    "        \n",
    "        inserted_count += len(data_to_insert)\n",
    "        print(f\"已插入 {inserted_count} 条记录...\")\n",
    "    \n",
    "    # Commit changes\n",
    "    conn.commit()\n",
    "    \n",
    "    print(f\"\\n完成！共插入 {inserted_count} 条记录到 train_dialogues 表\")\n",
    "    \n",
    "    # Verify the data\n",
    "    cursor_read.execute('SELECT COUNT(*) FROM train_dialogues')\n",
    "    count = cursor_read.fetchone()[0]\n",
    "    print(f\"验证：train_dialogues 表中共有 {count} 条记录\")\n",
    "    \n",
    "    # Show sample data\n",
    "    cursor_read.execute('SELECT * FROM train_dialogues LIMIT 3')\n",
    "    samples = cursor_read.fetchall()\n",
    "    print(\"\\n示例数据：\")\n",
    "    for sample in samples:\n",
    "        print(f\"  ID: {sample[0]}, 户晨风: {sample[1][:50]}..., 状态: {sample[3]}, 来源: {sample[4]}, 创建时间: {sample[5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"错误: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
